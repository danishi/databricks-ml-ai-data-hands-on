"""
Streamlit Databricks App: RAG ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ

ç¤¾å†…FAQãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’æ¤œç´¢ã—ã€LLMãŒå›ç­”ã‚’ç”Ÿæˆã™ã‚‹RAGãƒãƒ£ãƒƒãƒˆã‚¢ãƒ—ãƒªã§ã™ã€‚
Databricks Apps ã¨ã—ã¦ãƒ‡ãƒ—ãƒ­ã‚¤ã—ã¦ä½¿ç”¨ã—ã¾ã™ã€‚

=== ã“ã®ã‚¢ãƒ—ãƒªã®ä»•çµ„ã¿ï¼ˆRAG ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ï¼‰===

  ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè³ªå•ã‚’å…¥åŠ›
       â†“
  â‘  è³ªå•ã‚’ãƒ™ã‚¯ãƒˆãƒ«ï¼ˆæ•°å€¤é…åˆ—ï¼‰ã«å¤‰æ›ï¼ˆEmbeddingï¼‰
       â†“
  â‘¡ FAQãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¨ã®ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã‚’è¨ˆç®—ã—ã€é–¢é€£ã™ã‚‹FAQã‚’æ¤œç´¢
       â†“
  â‘¢ æ¤œç´¢çµæœ + è³ªå• ã‚’ LLM ã«æ¸¡ã—ã¦å›ç­”ã‚’ç”Ÿæˆï¼ˆGenerationï¼‰
       â†“
  å›ç­” + å‚ç…§å…ƒãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’è¡¨ç¤º

=== å‰ææ¡ä»¶ ===
- Foundation Model APIs ãŒæœ‰åŠ¹ãªãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹ã§ Databricks Apps ã¨ã—ã¦ãƒ‡ãƒ—ãƒ­ã‚¤
- genai/02_rag_chat.py ã®å†…å®¹ã‚’ç†è§£ã—ã¦ã„ã‚‹ã¨ã€ã‚³ãƒ¼ãƒ‰ã®æ„å‘³ãŒã‚ˆã‚Šã‚ã‹ã‚Šã¾ã™

=== ãƒ‡ãƒ—ãƒ­ã‚¤æ–¹æ³• ===
  1. Databricks ãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹ã®ã€Œã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã€â†’ã€Œã‚¢ãƒ—ãƒªã€ã‚’é¸æŠ
  2. ã€Œã‚¢ãƒ—ãƒªã®ä½œæˆã€ã‚’ã‚¯ãƒªãƒƒã‚¯
  3. ã‚¢ãƒ—ãƒªåã‚’å…¥åŠ›ï¼ˆä¾‹: rag-chat-appï¼‰ã—ä½œæˆ
  4. ã“ã®ãƒªãƒã‚¸ãƒˆãƒªã® app_rag/ ãƒ•ã‚©ãƒ«ãƒ€ã‚’ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ãƒ‘ã‚¹ã«æŒ‡å®š
  5. ãƒ‡ãƒ—ãƒ­ã‚¤ã‚’å®Ÿè¡Œ

=== ãƒ•ã‚¡ã‚¤ãƒ«æ§‹æˆ ===
  app_rag/
  â”œâ”€â”€ app.py              â† ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªï¼‰
  â””â”€â”€ requirements.txt    â† å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªä¸€è¦§
"""

import streamlit as st
import numpy as np
from openai import OpenAI
from databricks.sdk import WorkspaceClient

# --- ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(
    page_title="ç¤¾å†…FAQ RAGãƒãƒ£ãƒƒãƒˆ",
    page_icon="ğŸ’¬",
    layout="centered",
)

# --- å®šæ•° ---
LLM_MODEL = "databricks-meta-llama-3-3-70b-instruct"
EMBEDDING_MODEL = "databricks-gte-large-en"

# --- ç¤¾å†…FAQãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ ---
DOCUMENTS = [
    {
        "id": 1,
        "title": "ãƒªãƒ¢ãƒ¼ãƒˆãƒ¯ãƒ¼ã‚¯åˆ¶åº¦ã«ã¤ã„ã¦",
        "content": (
            "ãƒ†ãƒƒã‚¯ã‚³ãƒ¼ãƒãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§ã¯é€±3æ—¥ã¾ã§ãƒªãƒ¢ãƒ¼ãƒˆãƒ¯ãƒ¼ã‚¯ãŒå¯èƒ½ã§ã™ã€‚"
            "ãƒªãƒ¢ãƒ¼ãƒˆãƒ¯ãƒ¼ã‚¯ã‚’åˆ©ç”¨ã™ã‚‹å ´åˆã¯ã€å‰æ—¥ã¾ã§ã«ãƒãƒ¼ãƒ ãƒªãƒ¼ãƒ€ãƒ¼ã¸ç”³è«‹ã—ã¦ãã ã•ã„ã€‚"
            "ã‚³ã‚¢ã‚¿ã‚¤ãƒ ã¯10:00ã€œ15:00ã§ã™ã€‚"
            "ãƒªãƒ¢ãƒ¼ãƒˆãƒ¯ãƒ¼ã‚¯ç”¨ã®VPNæ¥ç¶šæ‰‹é †ã¯ç¤¾å†…ãƒãƒ¼ã‚¿ãƒ«ã®ã€ŒITè¨­å®šã‚¬ã‚¤ãƒ‰ã€ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚"
        ),
    },
    {
        "id": 2,
        "title": "æœ‰çµ¦ä¼‘æš‡ã®å–å¾—ã«ã¤ã„ã¦",
        "content": (
            "æœ‰çµ¦ä¼‘æš‡ã¯å…¥ç¤¾6ãƒ¶æœˆå¾Œã«10æ—¥ä»˜ä¸ã•ã‚Œã¾ã™ã€‚"
            "ç”³è«‹ã¯ä¼‘æš‡ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ï¼ˆHRãƒãƒ¼ã‚¿ãƒ«ï¼‰ã‹ã‚‰è¡Œã£ã¦ãã ã•ã„ã€‚"
            "3æ—¥ä»¥ä¸Šã®é€£ç¶šä¼‘æš‡ã¯2é€±é–“å‰ã¾ã§ã«ç”³è«‹ãŒå¿…è¦ã§ã™ã€‚"
            "åŠæ—¥å˜ä½ã§ã®å–å¾—ã‚‚å¯èƒ½ã§ã™ã€‚"
            "å¹´æœ«å¹´å§‹ï¼ˆ12/29ã€œ1/3ï¼‰ã¯ä¼šç¤¾æŒ‡å®šä¼‘æ—¥ã®ãŸã‚æœ‰çµ¦æ¶ˆåŒ–ã¯ä¸è¦ã§ã™ã€‚"
        ),
    },
    {
        "id": 3,
        "title": "çµŒè²»ç²¾ç®—ã®æ–¹æ³•",
        "content": (
            "çµŒè²»ç²¾ç®—ã¯çµŒè²»ç²¾ç®—ã‚·ã‚¹ãƒ†ãƒ ï¼ˆEXã‚·ã‚¹ãƒ†ãƒ ï¼‰ã‹ã‚‰ç”³è«‹ã—ã¦ãã ã•ã„ã€‚"
            "é ˜åæ›¸ã®åŸæœ¬ã¾ãŸã¯ã‚¹ã‚­ãƒ£ãƒ³ãƒ‡ãƒ¼ã‚¿ã®æ·»ä»˜ãŒå¿…é ˆã§ã™ã€‚"
            "äº¤é€šè²»ã¯æœˆæœ«ç· ã‚ç¿Œæœˆ15æ—¥æ‰•ã„ã§ã™ã€‚"
            "ã‚¿ã‚¯ã‚·ãƒ¼åˆ©ç”¨ã¯åŸå‰‡ã¨ã—ã¦äº‹å‰æ‰¿èªãŒå¿…è¦ã§ã™ã€‚ãŸã ã—çµ‚é›»å¾Œã®å¸°å®…ã¯äº‹å¾Œç”³è«‹å¯èƒ½ã§ã™ã€‚"
            "å‡ºå¼µæ™‚ã®å®¿æ³Šè²»ä¸Šé™ã¯1æ³Š12,000å††ã§ã™ã€‚"
        ),
    },
    {
        "id": 4,
        "title": "ç¤¾å†…å‹‰å¼·ä¼šãƒ»ç ”ä¿®åˆ¶åº¦",
        "content": (
            "ãƒ†ãƒƒã‚¯ã‚³ãƒ¼ãƒãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§ã¯æ¯é€±é‡‘æ›œæ—¥16:00ã€œ17:00ã«ç¤¾å†…Techå‹‰å¼·ä¼šã‚’é–‹å‚¬ã—ã¦ã„ã¾ã™ã€‚"
            "å¤–éƒ¨ã‚«ãƒ³ãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ã¸ã®å‚åŠ è²»ã¯å¹´é–“10ä¸‡å††ã¾ã§ä¼šç¤¾ãŒè² æ‹…ã—ã¾ã™ã€‚"
            "Udemyã€Courseraãªã©ã®ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å­¦ç¿’ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã®æ³•äººã‚¢ã‚«ã‚¦ãƒ³ãƒˆãŒåˆ©ç”¨å¯èƒ½ã§ã™ã€‚"
            "æ›¸ç±è³¼å…¥è²»ã¯æœˆé¡5,000å††ã¾ã§çµŒè²»ã¨ã—ã¦ç”³è«‹ã§ãã¾ã™ã€‚"
            "è³‡æ ¼å–å¾—æ™‚ã®å—é¨“æ–™ã¯åˆæ ¼ã—ãŸå ´åˆã«å…¨é¡ä¼šç¤¾è² æ‹…ã¨ãªã‚Šã¾ã™ã€‚"
        ),
    },
    {
        "id": 5,
        "title": "ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒãƒªã‚·ãƒ¼",
        "content": (
            "ç¤¾å¤–ã¸ã®ãƒ‡ãƒ¼ã‚¿æŒã¡å‡ºã—ã¯åŸå‰‡ç¦æ­¢ã§ã™ã€‚å¿…è¦ãªå ´åˆã¯ISMSç®¡ç†è€…ã®æ‰¿èªã‚’å¾—ã¦ãã ã•ã„ã€‚"
            "ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã¯12æ–‡å­—ä»¥ä¸Šã§ã€è‹±æ•°å­—è¨˜å·ã‚’å«ã‚€å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚90æ—¥ã”ã¨ã«å¤‰æ›´ã—ã¦ãã ã•ã„ã€‚"
            "ä¸å¯©ãªãƒ¡ãƒ¼ãƒ«ã‚’å—ä¿¡ã—ãŸå ´åˆã¯ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒãƒ¼ãƒ ï¼ˆsecurity@techcorp.example.comï¼‰ã«è»¢é€ã—ã¦ãã ã•ã„ã€‚"
            "å€‹äººæ‰€æœ‰ãƒ‡ãƒã‚¤ã‚¹ã§ã®æ¥­å‹™åˆ©ç”¨ï¼ˆBYODï¼‰ã¯ç”³è«‹åˆ¶ã§ã™ã€‚MDMã‚¢ãƒ—ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãŒå¿…é ˆã§ã™ã€‚"
        ),
    },
    {
        "id": 6,
        "title": "ç¦åˆ©åšç”Ÿã«ã¤ã„ã¦",
        "content": (
            "ãƒ†ãƒƒã‚¯ã‚³ãƒ¼ãƒãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®ç¦åˆ©åšç”Ÿã«ã¯ä»¥ä¸‹ãŒå«ã¾ã‚Œã¾ã™ã€‚"
            "å¥åº·è¨ºæ–­ã¯å¹´1å›ï¼ˆ35æ­³ä»¥ä¸Šã¯äººé–“ãƒ‰ãƒƒã‚¯ï¼‰ãŒä¼šç¤¾è² æ‹…ã§å—ã‘ã‚‰ã‚Œã¾ã™ã€‚"
            "ã‚¹ãƒãƒ¼ãƒ„ã‚¸ãƒ åˆ©ç”¨è£œåŠ©ã¨ã—ã¦æœˆé¡3,000å††ãŒæ”¯çµ¦ã•ã‚Œã¾ã™ã€‚"
            "ç¤¾å“¡é£Ÿå ‚ã¯æ˜¼é£Ÿ1é£Ÿ300å††ã§åˆ©ç”¨å¯èƒ½ã§ã™ã€‚"
            "è‚²å…ä¼‘æ¥­ã¯æœ€å¤§2å¹´é–“å–å¾—å¯èƒ½ã§ã€å¾©å¸°å¾Œã¯æ™‚çŸ­å‹¤å‹™åˆ¶åº¦ã‚‚åˆ©ç”¨ã§ãã¾ã™ã€‚"
            "çµå©šç¥é‡‘30,000å††ã€å‡ºç”£ç¥é‡‘50,000å††ãŒæ”¯çµ¦ã•ã‚Œã¾ã™ã€‚"
        ),
    },
    {
        "id": 7,
        "title": "é–‹ç™ºç’°å¢ƒã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—",
        "content": (
            "æ–°å…¥ç¤¾å“¡ã®é–‹ç™ºç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æ‰‹é †ã§ã™ã€‚"
            "1. ITéƒ¨é–€ã‹ã‚‰MacBookã¾ãŸã¯Windows PCã‚’å—ã‘å–ã‚Šã¾ã™ã€‚"
            "2. ç¤¾å†…GitLabã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®ä½œæˆã‚’ IT ãƒ˜ãƒ«ãƒ—ãƒ‡ã‚¹ã‚¯ã«ä¾é ¼ã—ã¦ãã ã•ã„ã€‚"
            "3. VPN ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆï¼ˆGlobalProtectï¼‰ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ã€‚"
            "4. Slack ã® #general ãƒãƒ£ãƒ³ãƒãƒ«ã«å‚åŠ ã—ã¦ãã ã•ã„ã€‚"
            "5. é–‹ç™ºç”¨ã®AWSã‚¢ã‚«ã‚¦ãƒ³ãƒˆãŒå¿…è¦ãªå ´åˆã¯ã‚¯ãƒ©ã‚¦ãƒ‰ãƒãƒ¼ãƒ ã«ç”³è«‹ã—ã¦ãã ã•ã„ã€‚"
        ),
    },
    {
        "id": 8,
        "title": "è©•ä¾¡åˆ¶åº¦ã¨æ˜‡çµ¦ã«ã¤ã„ã¦",
        "content": (
            "äººäº‹è©•ä¾¡ã¯å¹´2å›ï¼ˆ4æœˆã¨10æœˆï¼‰å®Ÿæ–½ã•ã‚Œã¾ã™ã€‚"
            "è©•ä¾¡ã¯ã€Œç›®æ¨™é”æˆåº¦ã€ã€Œè¡Œå‹•è©•ä¾¡ã€ã€Œ360åº¦ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã€ã®3è»¸ã§è¡Œã‚ã‚Œã¾ã™ã€‚"
            "æ˜‡çµ¦ã¯4æœˆã®è©•ä¾¡çµæœã«åŸºã¥ã7æœˆã«åæ˜ ã•ã‚Œã¾ã™ã€‚"
            "è³ä¸ã¯6æœˆã¨12æœˆã«æ”¯çµ¦ã•ã‚Œã€æ¥­ç¸¾é€£å‹•éƒ¨åˆ†ã¨å€‹äººè©•ä¾¡éƒ¨åˆ†ã§æ§‹æˆã•ã‚Œã¾ã™ã€‚"
            "ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼æ˜‡æ ¼ã«ã¯ç¤¾å†…ç ”ä¿®ã®ä¿®äº†ã¨éƒ¨é–€é•·ã®æ¨è–¦ãŒå¿…è¦ã§ã™ã€‚"
        ),
    },
]


@st.cache_resource
def get_openai_client():
    """Databricks Foundation Model APIs ç”¨ã®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’å–å¾—"""
    w = WorkspaceClient()
    host = w.config.host
    token = w.config.token
    return OpenAI(
        api_key=token,
        base_url=f"{host}/serving-endpoints",
    )


@st.cache_resource
def compute_document_embeddings():
    """å…¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®Embeddingã‚’äº‹å‰è¨ˆç®—ï¼ˆã‚¢ãƒ—ãƒªèµ·å‹•æ™‚ã«1å›ã ã‘å®Ÿè¡Œï¼‰"""
    openai_client = get_openai_client()
    texts = [doc["content"] for doc in DOCUMENTS]
    response = openai_client.embeddings.create(
        model=EMBEDDING_MODEL,
        input=texts,
    )
    return [item.embedding for item in response.data]


def cosine_similarity(a, b):
    """ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã‚’è¨ˆç®—"""
    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))


def search_documents(query: str, doc_embeddings: list, top_k: int = 3) -> list[dict]:
    """è³ªå•ã«é–¢é€£ã™ã‚‹ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢"""
    openai_client = get_openai_client()
    query_response = openai_client.embeddings.create(
        model=EMBEDDING_MODEL,
        input=[query],
    )
    query_embedding = query_response.data[0].embedding

    similarities = []
    for i, doc_emb in enumerate(doc_embeddings):
        sim = cosine_similarity(query_embedding, doc_emb)
        similarities.append((i, sim))

    similarities.sort(key=lambda x: x[1], reverse=True)

    results = []
    for idx, sim in similarities[:top_k]:
        results.append({
            "document": DOCUMENTS[idx],
            "similarity": sim,
        })
    return results


def generate_rag_response(query: str, search_results: list) -> str:
    """æ¤œç´¢çµæœã‚’ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦LLMã«å›ç­”ã‚’ç”Ÿæˆã•ã›ã‚‹"""
    openai_client = get_openai_client()

    context_parts = []
    for r in search_results:
        doc = r["document"]
        context_parts.append(f"ã€{doc['title']}ã€‘\n{doc['content']}")
    context = "\n\n".join(context_parts)

    system_prompt = (
        "ã‚ãªãŸã¯ç¤¾å†…FAQã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚\n"
        "ä»¥ä¸‹ã®ã€Œå‚è€ƒæƒ…å ±ã€ã®ã¿ã«åŸºã¥ã„ã¦è³ªå•ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚\n"
        "å‚è€ƒæƒ…å ±ã«è¨˜è¼‰ãŒãªã„å†…å®¹ã«ã¤ã„ã¦ã¯ã€Œã“ã®æƒ…å ±ã¯ç¤¾å†…FAQã«è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€ã¨å›ç­”ã—ã¦ãã ã•ã„ã€‚\n"
        "å›ç­”ã¯ç°¡æ½”ã‹ã¤æ­£ç¢ºã«ãŠé¡˜ã„ã—ã¾ã™ã€‚"
    )

    user_prompt = f"## å‚è€ƒæƒ…å ±\n\n{context}\n\n## è³ªå•\n\n{query}"

    response = openai_client.chat.completions.create(
        model=LLM_MODEL,
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt},
        ],
        max_tokens=512,
        temperature=0.0,
    )
    return response.choices[0].message.content


def main():
    st.title("ç¤¾å†…FAQ RAGãƒãƒ£ãƒƒãƒˆ")
    st.caption("ç¤¾å†…ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ã‚‚ã¨ã«ã€AIãŒè³ªå•ã«å›ç­”ã—ã¾ã™ï¼ˆRAG: æ¤œç´¢æ‹¡å¼µç”Ÿæˆï¼‰")

    # ã‚µã‚¤ãƒ‰ãƒãƒ¼: ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä¸€è¦§ã‚’è¡¨ç¤º
    with st.sidebar:
        st.subheader("æ¤œç´¢å¯¾è±¡ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ")
        for doc in DOCUMENTS:
            with st.expander(f"[{doc['id']}] {doc['title']}"):
                st.write(doc["content"])
        st.divider()
        st.caption("ã“ã‚Œã‚‰ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‹ã‚‰RAGã§æ¤œç´¢ãƒ»å›ç­”ã—ã¾ã™")

    # Embedding ã®äº‹å‰è¨ˆç®—
    doc_embeddings = compute_document_embeddings()

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’è¡¨ç¤º
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])
            if "sources" in msg:
                with st.expander("å‚ç…§å…ƒãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ"):
                    for src in msg["sources"]:
                        st.write(f"- {src['title']} (é¡ä¼¼åº¦: {src['similarity']:.4f})")

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›
    if prompt := st.chat_input("ç¤¾å†…åˆ¶åº¦ã«ã¤ã„ã¦è³ªå•ã—ã¦ãã ã•ã„ï¼ˆä¾‹: ãƒªãƒ¢ãƒ¼ãƒˆãƒ¯ãƒ¼ã‚¯ã¯ä½•æ—¥ã¾ã§ï¼Ÿï¼‰"):
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤ºãƒ»ä¿å­˜
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        # RAGã§å›ç­”ã‚’ç”Ÿæˆ
        with st.chat_message("assistant"):
            with st.spinner("æ¤œç´¢ä¸­..."):
                search_results = search_documents(prompt, doc_embeddings, top_k=3)

            with st.spinner("å›ç­”ã‚’ç”Ÿæˆä¸­..."):
                answer = generate_rag_response(prompt, search_results)

            st.markdown(answer)

            # å‚ç…§å…ƒã‚’è¡¨ç¤º
            sources = [
                {"title": r["document"]["title"], "similarity": r["similarity"]}
                for r in search_results
            ]
            with st.expander("å‚ç…§å…ƒãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ"):
                for src in sources:
                    st.write(f"- {src['title']} (é¡ä¼¼åº¦: {src['similarity']:.4f})")

        # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä¿å­˜
        st.session_state.messages.append({
            "role": "assistant",
            "content": answer,
            "sources": sources,
        })


if __name__ == "__main__":
    main()
